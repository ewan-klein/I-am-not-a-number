\subsection{Perceptions of monitoring}
\label{sec:perc-monit}
There were mixed perceptions of the monitoring project, and we
identified three archetypal responses, summarised as follows: 

\begin{enumerate}
\item \textit{I don't care} --- I'm already being monitored in so many ways
  that are so much more personal e.g., CCTV in the building, mobile
  phone apps, etc. 
\item \textit{Data is great} --- There are so many ways that we could use
  data like this to improve our work experience. I'd
  be happy to be monitored in even more personal ways if that would
  bring benefit to me. 
\item \textit{Show me the change} --- Is all this monitoring really necessary?
  Can I see what data you’re collecting? Will the data actually be
  used to inform a change? How will I know if it is? Might there be
  easier or simpler ways to achieve the necessary change? 
\end{enumerate}

The first archetype was typically either an under- or well-informed
person who was not likely to react negatively to the monitoring. The
second archetype was typically a person with previous experience of
using sensors or data analytics in their work. They were not likely to
react negatively to the monitoring and were eager to contribute ideas
and suggestions about more monitoring options and how they could be
used to improve user experience. The third response was the most
common and represents people with the most potential to view IoT
initiatives skeptically or negatively. The majority of participants
who fell in the third category were nevertheless willing to engage or
be engaged.

The responses of our study participants
indicate that are number of challenges to be addressed in engaging
with users when deploying IoT applications in offices and other
places of work. 

\subsection{Privacy and Transparency}
\label{sec:privacy}

Privacy was not a primary concern of our study. Nevertheless,
reflections on privacy and surveillance surfaced frequently in the
comments of the study participants.

We can frame some of these concerns in terms of \term{information
    spaces} \cite{Jiang-2002-MPCI} ins the sense of ``a way to organize information, resources, and services
  around important privacy-relevant context factors.\ldots\  A
  \term{boundary}---physical, social, or activity-based---delimits an
  information space.'' In the monitoring experiment, physical boundaries were clearly
important in determining information-spaces. We chose to monitor a meeting room
specifically because it was a common space, not linked to any specific
individuals, and therefore less likely to trigger privacy
concerns. Conversely, the desks that people occupied in the open plan
offices defined a much more personal information spaces, albeit not
demarcated by such clearcut physical boundaries. It is clear from
comments in Section~\ref{sec:results} that many participants saw
monitoring of their desks as a source of concern, even though this was never
proposed as an extension of the meeting room monitoring.

The chairs in the monitored meeting room were somewhat less easy to
classify in this scheme. Again, they can be regarded as information
spaces, given that sensors were attached to them. And although they
are only transiently associated with any one individual (i.e., for the
duration of a meeting), the study results show that several participants were
sensitive about the physical closeness of the
sensors. \cite{Ohara-2016-TSVP} proposes to characterise a breach of privacy as
the state which arises when one of `my' boundaries are crossed, and if
I feel that 'my chair' or 'my-body-on-the-chair' is being monitored,
this can be perceived as intrusive. 

O'Hara's \cite{Ohara-2016-TSVP} approach to privacy involves seven
`levels', of which the first level is occupied by the \term{underlying
  concept of privacy}---provisionally identified in terms whether a
signifcant boundary has been crossed. The second privacy level concerns the \term{empirical
  facts} of the matter. The monitoring project took steps to ensure
that no personal data was collected by the sensors; in particular, the
chair sensors were configured in such a way that they only allow binary
discrimination, namely was a `sitting' event detected at a given
measuring period or not.

 O'Hara's third level is characterised in terms
of phenomenology: regardless of the empirical facts, how is the
situation perceived by the subject. In the case of, say, social media
platform, I may feel that I am having a private conversation with a
friend, unaware that in fact a lot of information is being collected
by the social network platform owner. However, if the presence of IoT
monitoring devices are explicitly signalled to a user, and indeed have
a visible form factor, then the converse perception of being
surveilled is hard to avoid.

In terms of a deploying an IoT monitoring system, we are therefore
confronted by the problem of a potential discrepancy between privacy
levels two and level three: we are not collecting personal data, but
the physical devices being used may prompt concerns from people that
the opposite is true. Ideally, we would like to be able to make
evident that the data flow from sensor to processing system carries no
personal information. This borrows from the notion of
\term{computational accountability} discussed in
\cite{Crabtree-2016-BAIT}: ``the surfacing or making visible of
computational behaviours or actions to better enable human-computer
interactions.

\subsection{Purpose and Values}
\label{sec:communication-values}

As pointed out in Section~\ref{sec:introduction}, most discussions of IoT
systems and reference architectures
\cite{Puschel-2016-WIAS,Heidt-2016-PGFT} focus on technology stacks
and engineering concerns with human actors being relegated to the
margins.

Management
relationships and trust For a number of respondents, the key issues
was the relationship between management and employees and what was
communicated through that relationship. There was a lot of concern
that monitoring that started out for one purpose could be exploited
for another, depending on the type of manager.  It all depends on how
the data is used – single biggest concern = management (not bothered
by general environmental monitoring, but individual monitoring e.g. of
desk use more concerning – not as much concerned about facilities
managers as bosses) 






With top-down - or management or technophile-driven - experiments,
there is likely to be some disjunct between the vision of what could
or should be achieved (what is promised) and what is actually
delivered or accomplished. … “over-collection” of data 
…
We might define a ‘successful’ experiment as one that leads to
awareness, acceptability and trust. Or we could define it as an
experiment that either a) accomplishes the experimenter’s goals
without adverse reactions or b) involves participants in co-creating
the goals and leads to a positive experience that IoT has
‘accomplished’ something for the participants.  

We propose three principles for awareness, acceptability and trust.

\paragraph{Transparency} Anyone affected by the monitoring should be
informed about what data is being collected and should be able to
access an easily interpretable explanation of this, for example
through data visualisation. Physical signage in monitored areas is
more effective than email communication. If possible, some version of
the raw data should be accessible to anyone interested in exploring it
and comparing their interpretations to that of the decision-makers. 

\paragraph{Purpose} Monitoring should be a time-bounded activity with
a clearly defined purpose. Individuals who might be affected by the
monitoring should be informed about the what, why and how of decisions
made based on the data collected. Overmonitoring by “well-meaning
technophiles” should be avoided when simpler interventions could
achieve the desired goal. 

\paragraph{Participation} In the case of workplace monitoring, there
is an opportunity and a need to move beyond the narratives of resource
efficiency, maximising productivity and incentivising specific
behaviours. Trust in management decision-making has been compromised
by the use of data to justify cost-cutting and provide only a minimum
acceptable level of facilities and resources. 

New narratives built around trust and valuing individuals can be
created by involving employees in identifying the issues that most
affect their performance, comfort, health and well-being and
determining how and whether monitoring could be used to address these
issues effectively. The engagement process can be structured to offer
employees freedom, creativity, and a sense of agency. 

The narrative of the value of the Internet of Things to maximise
resource efficiency and improve user experience is widely embedded and
offers a seemingly easy ‘quick win’ application. However, how such an
application is designed and delivered can influence its acceptability
and either limit or expand its potential to create shared value. These
three guidelines can help to overcome skepticism and ensure that IoT
monitoring projects incorporate a broader set of values and
beneficiaries. 

%%% Local Variables: ***
%%% mode:latex ***
%%% TeX-master: "main.tex"  ***
%%% End: ***
